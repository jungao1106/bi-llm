{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "}\n",
    "files['train'] = '/data/gj/data/imdb/train.json'\n",
    "files['test'] = '/data/gj/data/imdb/test.json'\n",
    "\n",
    "raws = load_dataset('json', data_files=files, cache_dir='/data/gj/Bi-Attention-HFTrainer/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_\n",
    "xxx = load_from_disk('/data/gj/data/imdb/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaConfig\n",
    "\n",
    "config = LlamaConfig.from_pretrained('/data/gj/llama-7b-hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.is_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartConfig\n",
    "cfg = BartConfig.from_pretrained('/data/gj/bart-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.is_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastchat.model.model_adapter import get_conversation_template\n",
    "\n",
    "conv = get_conversation_template('vicuna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained('/data/gj/vicuna-7b-v1.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(conv.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "s = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"])\n",
    "x = s.score('gao jun', 'gao ju')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(x['rouge1']*100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = '10.40.6.125:7890'\n",
    "os.environ['https_proxy'] = '10.40.6.125:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoPeftModelForCausalLM.from_pretrained('/data/gj/Bi-Attention-HFTrainer/output_dir/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import evaluate\n",
    "\n",
    "os.environ['http_proxy'] = '10.40.51.67:7890'\n",
    "os.environ['https_proxy'] = '10.40.51.67:7890'\n",
    "\n",
    "acc = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER']]\n",
    "y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'B-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER']]\n",
    "\n",
    "acc.compute(predictions=y_pred, references=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'a': 1, 'b': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {v: k for k, v in x.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = nn.functional.softmax(torch.randn((9, 9)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in x for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.arange(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def map_numbers_to_letters(matrix, mapping):\n",
    "    map_func = np.vectorize(lambda num: mapping.get(num, ' '))\n",
    "    letter_matrix = map_func(matrix)\n",
    "    return letter_matrix\n",
    "\n",
    "# 示例字典和矩阵\n",
    "letter_mapping = {1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E'}\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_numbers_to_letters(matrix, letter_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.remove(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.masked_fill(x<0.2, -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.randn((3, 4)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.masked_fill(m.unsqueeze(dim=-1), -100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.random.random((4, 5))\n",
    "lables = np.random.random((4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(lables<0.5, preds, np.full_like(lables, -100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_ner_tags_mapping = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "conll_ner_tags_mapping = {v: k for k, v in conll_ner_tags_mapping.items()}\n",
    "\n",
    "\n",
    "def postprocess_ner_ids(preds, labels):\n",
    "    map_func = np.vectorize(lambda num: conll_ner_tags_mapping.get(num, ''))\n",
    "    preds = np.where(labels != -100, preds, np.full_like(preds, -100))\n",
    "    preds = map_func(preds).tolist()\n",
    "    labels = map_func(labels).tolist()\n",
    "    \n",
    "    for pred in preds:\n",
    "        pred[:] = [p for p in pred if p != '']\n",
    "            \n",
    "    for label in labels:\n",
    "        label[:] = [l for l in label if l != '']\n",
    "    \n",
    "    return preds, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([[1,2,3], [4,5,6]])\n",
    "labels = np.array([[-100, 2, -100], [-100, 5, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = postprocess_ner_ids(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import os\n",
    "os.environ['http_proxy'] = '10.40.51.67:7890'\n",
    "os.environ['https_proxy'] = '10.40.51.67:7890'\n",
    "metric = evaluate.load('seqeval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.tolist().pop('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/gj/miniconda3/envs/biattention/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
       " 'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
       " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 0.5,\n",
       " 'overall_recall': 0.3333333333333333,\n",
       " 'overall_f1': 0.4,\n",
       " 'overall_accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'x': 50.0, 'y': 40.0}, 'b': 60.0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply(result, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/gj/miniconda3/envs/biattention/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-21 19:31:50,717] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.44s/it]\n",
      "Some weights of the model checkpoint at /data/gj/models/vicuna-7b-v1.3 were not used when initializing LlamaModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing LlamaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained('/data/gj/Bi-Attention-HFTrainer/output_dir/test/checkpoint-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = safetensors.torch.load_file('/data/gj/Bi-Attention-HFTrainer/output_dir/test/checkpoint-4/adapter_model.safetensors', device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = safetensors.torch.load_file('/data/gj/Bi-Attention-HFTrainer/output_dir/test/checkpoint-8/adapter_model.safetensors', device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1198e-02, -1.8330e-03,  1.5624e-02,  ...,  1.4411e-02,\n",
       "          6.1283e-03,  1.5579e-02],\n",
       "        [-7.6152e-03,  6.2727e-03, -1.3887e-02,  ...,  9.2982e-03,\n",
       "         -1.1437e-05, -5.0887e-04],\n",
       "        [-1.4586e-02, -7.0003e-03,  1.2569e-02,  ...,  7.8880e-03,\n",
       "         -7.2497e-03, -7.3856e-03],\n",
       "        ...,\n",
       "        [-9.9548e-03, -3.0787e-04,  7.9469e-03,  ...,  3.0999e-03,\n",
       "         -1.4552e-02, -8.0941e-03],\n",
       "        [ 8.8106e-03, -9.5266e-03, -8.2273e-03,  ..., -1.1473e-02,\n",
       "          8.0957e-03, -1.3063e-02],\n",
       "        [ 7.1870e-03, -2.7483e-03, -9.8101e-03,  ..., -3.1905e-03,\n",
       "          1.1243e-02, -1.3782e-02]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['base_model.model.layers.0.self_attn.k_proj.lora_A.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.1198e-02, -1.8330e-03,  1.5624e-02,  ...,  1.4411e-02,\n",
      "          6.1283e-03,  1.5579e-02],\n",
      "        [-7.6152e-03,  6.2727e-03, -1.3887e-02,  ...,  9.2982e-03,\n",
      "         -1.1437e-05, -5.0887e-04],\n",
      "        [-1.4586e-02, -7.0003e-03,  1.2569e-02,  ...,  7.8880e-03,\n",
      "         -7.2497e-03, -7.3856e-03],\n",
      "        ...,\n",
      "        [-9.9548e-03, -3.0787e-04,  7.9469e-03,  ...,  3.0999e-03,\n",
      "         -1.4552e-02, -8.0941e-03],\n",
      "        [ 8.8106e-03, -9.5266e-03, -8.2273e-03,  ..., -1.1473e-02,\n",
      "          8.0957e-03, -1.3063e-02],\n",
      "        [ 7.1870e-03, -2.7483e-03, -9.8101e-03,  ..., -3.1905e-03,\n",
      "          1.1243e-02, -1.3782e-02]])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if 'lora' in n:\n",
    "        print(p)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base_model.model.layers.0.self_attn.k_proj.lora_A.default.weight'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {k[:-6]+'default.weight': v for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.layers.9.self_attn.v_proj.lora_B.default.weight'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['base_model.model.embed_tokens.weight', 'base_model.model.layers.0.self_attn.q_proj.weight', 'base_model.model.layers.0.self_attn.k_proj.weight', 'base_model.model.layers.0.self_attn.v_proj.weight', 'base_model.model.layers.0.self_attn.o_proj.weight', 'base_model.model.layers.0.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.0.mlp.gate_proj.weight', 'base_model.model.layers.0.mlp.down_proj.weight', 'base_model.model.layers.0.mlp.up_proj.weight', 'base_model.model.layers.0.input_layernorm.weight', 'base_model.model.layers.0.post_attention_layernorm.weight', 'base_model.model.layers.1.self_attn.q_proj.weight', 'base_model.model.layers.1.self_attn.k_proj.weight', 'base_model.model.layers.1.self_attn.v_proj.weight', 'base_model.model.layers.1.self_attn.o_proj.weight', 'base_model.model.layers.1.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.1.mlp.gate_proj.weight', 'base_model.model.layers.1.mlp.down_proj.weight', 'base_model.model.layers.1.mlp.up_proj.weight', 'base_model.model.layers.1.input_layernorm.weight', 'base_model.model.layers.1.post_attention_layernorm.weight', 'base_model.model.layers.2.self_attn.q_proj.weight', 'base_model.model.layers.2.self_attn.k_proj.weight', 'base_model.model.layers.2.self_attn.v_proj.weight', 'base_model.model.layers.2.self_attn.o_proj.weight', 'base_model.model.layers.2.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.2.mlp.gate_proj.weight', 'base_model.model.layers.2.mlp.down_proj.weight', 'base_model.model.layers.2.mlp.up_proj.weight', 'base_model.model.layers.2.input_layernorm.weight', 'base_model.model.layers.2.post_attention_layernorm.weight', 'base_model.model.layers.3.self_attn.q_proj.weight', 'base_model.model.layers.3.self_attn.k_proj.weight', 'base_model.model.layers.3.self_attn.v_proj.weight', 'base_model.model.layers.3.self_attn.o_proj.weight', 'base_model.model.layers.3.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.3.mlp.gate_proj.weight', 'base_model.model.layers.3.mlp.down_proj.weight', 'base_model.model.layers.3.mlp.up_proj.weight', 'base_model.model.layers.3.input_layernorm.weight', 'base_model.model.layers.3.post_attention_layernorm.weight', 'base_model.model.layers.4.self_attn.q_proj.weight', 'base_model.model.layers.4.self_attn.k_proj.weight', 'base_model.model.layers.4.self_attn.v_proj.weight', 'base_model.model.layers.4.self_attn.o_proj.weight', 'base_model.model.layers.4.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.4.mlp.gate_proj.weight', 'base_model.model.layers.4.mlp.down_proj.weight', 'base_model.model.layers.4.mlp.up_proj.weight', 'base_model.model.layers.4.input_layernorm.weight', 'base_model.model.layers.4.post_attention_layernorm.weight', 'base_model.model.layers.5.self_attn.q_proj.weight', 'base_model.model.layers.5.self_attn.k_proj.weight', 'base_model.model.layers.5.self_attn.v_proj.weight', 'base_model.model.layers.5.self_attn.o_proj.weight', 'base_model.model.layers.5.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.5.mlp.gate_proj.weight', 'base_model.model.layers.5.mlp.down_proj.weight', 'base_model.model.layers.5.mlp.up_proj.weight', 'base_model.model.layers.5.input_layernorm.weight', 'base_model.model.layers.5.post_attention_layernorm.weight', 'base_model.model.layers.6.self_attn.q_proj.weight', 'base_model.model.layers.6.self_attn.k_proj.weight', 'base_model.model.layers.6.self_attn.v_proj.weight', 'base_model.model.layers.6.self_attn.o_proj.weight', 'base_model.model.layers.6.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.6.mlp.gate_proj.weight', 'base_model.model.layers.6.mlp.down_proj.weight', 'base_model.model.layers.6.mlp.up_proj.weight', 'base_model.model.layers.6.input_layernorm.weight', 'base_model.model.layers.6.post_attention_layernorm.weight', 'base_model.model.layers.7.self_attn.q_proj.weight', 'base_model.model.layers.7.self_attn.k_proj.weight', 'base_model.model.layers.7.self_attn.v_proj.weight', 'base_model.model.layers.7.self_attn.o_proj.weight', 'base_model.model.layers.7.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.7.mlp.gate_proj.weight', 'base_model.model.layers.7.mlp.down_proj.weight', 'base_model.model.layers.7.mlp.up_proj.weight', 'base_model.model.layers.7.input_layernorm.weight', 'base_model.model.layers.7.post_attention_layernorm.weight', 'base_model.model.layers.8.self_attn.q_proj.weight', 'base_model.model.layers.8.self_attn.k_proj.weight', 'base_model.model.layers.8.self_attn.v_proj.weight', 'base_model.model.layers.8.self_attn.o_proj.weight', 'base_model.model.layers.8.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.8.mlp.gate_proj.weight', 'base_model.model.layers.8.mlp.down_proj.weight', 'base_model.model.layers.8.mlp.up_proj.weight', 'base_model.model.layers.8.input_layernorm.weight', 'base_model.model.layers.8.post_attention_layernorm.weight', 'base_model.model.layers.9.self_attn.q_proj.weight', 'base_model.model.layers.9.self_attn.k_proj.weight', 'base_model.model.layers.9.self_attn.v_proj.weight', 'base_model.model.layers.9.self_attn.o_proj.weight', 'base_model.model.layers.9.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.9.mlp.gate_proj.weight', 'base_model.model.layers.9.mlp.down_proj.weight', 'base_model.model.layers.9.mlp.up_proj.weight', 'base_model.model.layers.9.input_layernorm.weight', 'base_model.model.layers.9.post_attention_layernorm.weight', 'base_model.model.layers.10.self_attn.q_proj.weight', 'base_model.model.layers.10.self_attn.k_proj.weight', 'base_model.model.layers.10.self_attn.v_proj.weight', 'base_model.model.layers.10.self_attn.o_proj.weight', 'base_model.model.layers.10.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.10.mlp.gate_proj.weight', 'base_model.model.layers.10.mlp.down_proj.weight', 'base_model.model.layers.10.mlp.up_proj.weight', 'base_model.model.layers.10.input_layernorm.weight', 'base_model.model.layers.10.post_attention_layernorm.weight', 'base_model.model.layers.11.self_attn.q_proj.weight', 'base_model.model.layers.11.self_attn.k_proj.weight', 'base_model.model.layers.11.self_attn.v_proj.weight', 'base_model.model.layers.11.self_attn.o_proj.weight', 'base_model.model.layers.11.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.11.mlp.gate_proj.weight', 'base_model.model.layers.11.mlp.down_proj.weight', 'base_model.model.layers.11.mlp.up_proj.weight', 'base_model.model.layers.11.input_layernorm.weight', 'base_model.model.layers.11.post_attention_layernorm.weight', 'base_model.model.layers.12.self_attn.q_proj.weight', 'base_model.model.layers.12.self_attn.k_proj.weight', 'base_model.model.layers.12.self_attn.v_proj.weight', 'base_model.model.layers.12.self_attn.o_proj.weight', 'base_model.model.layers.12.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.12.mlp.gate_proj.weight', 'base_model.model.layers.12.mlp.down_proj.weight', 'base_model.model.layers.12.mlp.up_proj.weight', 'base_model.model.layers.12.input_layernorm.weight', 'base_model.model.layers.12.post_attention_layernorm.weight', 'base_model.model.layers.13.self_attn.q_proj.weight', 'base_model.model.layers.13.self_attn.k_proj.weight', 'base_model.model.layers.13.self_attn.v_proj.weight', 'base_model.model.layers.13.self_attn.o_proj.weight', 'base_model.model.layers.13.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.13.mlp.gate_proj.weight', 'base_model.model.layers.13.mlp.down_proj.weight', 'base_model.model.layers.13.mlp.up_proj.weight', 'base_model.model.layers.13.input_layernorm.weight', 'base_model.model.layers.13.post_attention_layernorm.weight', 'base_model.model.layers.14.self_attn.q_proj.weight', 'base_model.model.layers.14.self_attn.k_proj.weight', 'base_model.model.layers.14.self_attn.v_proj.weight', 'base_model.model.layers.14.self_attn.o_proj.weight', 'base_model.model.layers.14.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.14.mlp.gate_proj.weight', 'base_model.model.layers.14.mlp.down_proj.weight', 'base_model.model.layers.14.mlp.up_proj.weight', 'base_model.model.layers.14.input_layernorm.weight', 'base_model.model.layers.14.post_attention_layernorm.weight', 'base_model.model.layers.15.self_attn.q_proj.weight', 'base_model.model.layers.15.self_attn.k_proj.weight', 'base_model.model.layers.15.self_attn.v_proj.weight', 'base_model.model.layers.15.self_attn.o_proj.weight', 'base_model.model.layers.15.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.15.mlp.gate_proj.weight', 'base_model.model.layers.15.mlp.down_proj.weight', 'base_model.model.layers.15.mlp.up_proj.weight', 'base_model.model.layers.15.input_layernorm.weight', 'base_model.model.layers.15.post_attention_layernorm.weight', 'base_model.model.layers.16.self_attn.q_proj.weight', 'base_model.model.layers.16.self_attn.k_proj.weight', 'base_model.model.layers.16.self_attn.v_proj.weight', 'base_model.model.layers.16.self_attn.o_proj.weight', 'base_model.model.layers.16.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.16.mlp.gate_proj.weight', 'base_model.model.layers.16.mlp.down_proj.weight', 'base_model.model.layers.16.mlp.up_proj.weight', 'base_model.model.layers.16.input_layernorm.weight', 'base_model.model.layers.16.post_attention_layernorm.weight', 'base_model.model.layers.17.self_attn.q_proj.weight', 'base_model.model.layers.17.self_attn.k_proj.weight', 'base_model.model.layers.17.self_attn.v_proj.weight', 'base_model.model.layers.17.self_attn.o_proj.weight', 'base_model.model.layers.17.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.17.mlp.gate_proj.weight', 'base_model.model.layers.17.mlp.down_proj.weight', 'base_model.model.layers.17.mlp.up_proj.weight', 'base_model.model.layers.17.input_layernorm.weight', 'base_model.model.layers.17.post_attention_layernorm.weight', 'base_model.model.layers.18.self_attn.q_proj.weight', 'base_model.model.layers.18.self_attn.k_proj.weight', 'base_model.model.layers.18.self_attn.v_proj.weight', 'base_model.model.layers.18.self_attn.o_proj.weight', 'base_model.model.layers.18.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.18.mlp.gate_proj.weight', 'base_model.model.layers.18.mlp.down_proj.weight', 'base_model.model.layers.18.mlp.up_proj.weight', 'base_model.model.layers.18.input_layernorm.weight', 'base_model.model.layers.18.post_attention_layernorm.weight', 'base_model.model.layers.19.self_attn.q_proj.weight', 'base_model.model.layers.19.self_attn.k_proj.weight', 'base_model.model.layers.19.self_attn.v_proj.weight', 'base_model.model.layers.19.self_attn.o_proj.weight', 'base_model.model.layers.19.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.19.mlp.gate_proj.weight', 'base_model.model.layers.19.mlp.down_proj.weight', 'base_model.model.layers.19.mlp.up_proj.weight', 'base_model.model.layers.19.input_layernorm.weight', 'base_model.model.layers.19.post_attention_layernorm.weight', 'base_model.model.layers.20.self_attn.q_proj.weight', 'base_model.model.layers.20.self_attn.k_proj.weight', 'base_model.model.layers.20.self_attn.v_proj.weight', 'base_model.model.layers.20.self_attn.o_proj.weight', 'base_model.model.layers.20.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.20.mlp.gate_proj.weight', 'base_model.model.layers.20.mlp.down_proj.weight', 'base_model.model.layers.20.mlp.up_proj.weight', 'base_model.model.layers.20.input_layernorm.weight', 'base_model.model.layers.20.post_attention_layernorm.weight', 'base_model.model.layers.21.self_attn.q_proj.weight', 'base_model.model.layers.21.self_attn.k_proj.weight', 'base_model.model.layers.21.self_attn.v_proj.weight', 'base_model.model.layers.21.self_attn.o_proj.weight', 'base_model.model.layers.21.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.21.mlp.gate_proj.weight', 'base_model.model.layers.21.mlp.down_proj.weight', 'base_model.model.layers.21.mlp.up_proj.weight', 'base_model.model.layers.21.input_layernorm.weight', 'base_model.model.layers.21.post_attention_layernorm.weight', 'base_model.model.layers.22.self_attn.q_proj.weight', 'base_model.model.layers.22.self_attn.k_proj.weight', 'base_model.model.layers.22.self_attn.v_proj.weight', 'base_model.model.layers.22.self_attn.o_proj.weight', 'base_model.model.layers.22.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.22.mlp.gate_proj.weight', 'base_model.model.layers.22.mlp.down_proj.weight', 'base_model.model.layers.22.mlp.up_proj.weight', 'base_model.model.layers.22.input_layernorm.weight', 'base_model.model.layers.22.post_attention_layernorm.weight', 'base_model.model.layers.23.self_attn.q_proj.weight', 'base_model.model.layers.23.self_attn.k_proj.weight', 'base_model.model.layers.23.self_attn.v_proj.weight', 'base_model.model.layers.23.self_attn.o_proj.weight', 'base_model.model.layers.23.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.23.mlp.gate_proj.weight', 'base_model.model.layers.23.mlp.down_proj.weight', 'base_model.model.layers.23.mlp.up_proj.weight', 'base_model.model.layers.23.input_layernorm.weight', 'base_model.model.layers.23.post_attention_layernorm.weight', 'base_model.model.layers.24.self_attn.q_proj.weight', 'base_model.model.layers.24.self_attn.k_proj.weight', 'base_model.model.layers.24.self_attn.v_proj.weight', 'base_model.model.layers.24.self_attn.o_proj.weight', 'base_model.model.layers.24.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.24.mlp.gate_proj.weight', 'base_model.model.layers.24.mlp.down_proj.weight', 'base_model.model.layers.24.mlp.up_proj.weight', 'base_model.model.layers.24.input_layernorm.weight', 'base_model.model.layers.24.post_attention_layernorm.weight', 'base_model.model.layers.25.self_attn.q_proj.weight', 'base_model.model.layers.25.self_attn.k_proj.weight', 'base_model.model.layers.25.self_attn.v_proj.weight', 'base_model.model.layers.25.self_attn.o_proj.weight', 'base_model.model.layers.25.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.25.mlp.gate_proj.weight', 'base_model.model.layers.25.mlp.down_proj.weight', 'base_model.model.layers.25.mlp.up_proj.weight', 'base_model.model.layers.25.input_layernorm.weight', 'base_model.model.layers.25.post_attention_layernorm.weight', 'base_model.model.layers.26.self_attn.q_proj.weight', 'base_model.model.layers.26.self_attn.k_proj.weight', 'base_model.model.layers.26.self_attn.v_proj.weight', 'base_model.model.layers.26.self_attn.o_proj.weight', 'base_model.model.layers.26.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.26.mlp.gate_proj.weight', 'base_model.model.layers.26.mlp.down_proj.weight', 'base_model.model.layers.26.mlp.up_proj.weight', 'base_model.model.layers.26.input_layernorm.weight', 'base_model.model.layers.26.post_attention_layernorm.weight', 'base_model.model.layers.27.self_attn.q_proj.weight', 'base_model.model.layers.27.self_attn.k_proj.weight', 'base_model.model.layers.27.self_attn.v_proj.weight', 'base_model.model.layers.27.self_attn.o_proj.weight', 'base_model.model.layers.27.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.27.mlp.gate_proj.weight', 'base_model.model.layers.27.mlp.down_proj.weight', 'base_model.model.layers.27.mlp.up_proj.weight', 'base_model.model.layers.27.input_layernorm.weight', 'base_model.model.layers.27.post_attention_layernorm.weight', 'base_model.model.layers.28.self_attn.q_proj.weight', 'base_model.model.layers.28.self_attn.k_proj.weight', 'base_model.model.layers.28.self_attn.v_proj.weight', 'base_model.model.layers.28.self_attn.o_proj.weight', 'base_model.model.layers.28.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.28.mlp.gate_proj.weight', 'base_model.model.layers.28.mlp.down_proj.weight', 'base_model.model.layers.28.mlp.up_proj.weight', 'base_model.model.layers.28.input_layernorm.weight', 'base_model.model.layers.28.post_attention_layernorm.weight', 'base_model.model.layers.29.self_attn.q_proj.weight', 'base_model.model.layers.29.self_attn.k_proj.weight', 'base_model.model.layers.29.self_attn.v_proj.weight', 'base_model.model.layers.29.self_attn.o_proj.weight', 'base_model.model.layers.29.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.29.mlp.gate_proj.weight', 'base_model.model.layers.29.mlp.down_proj.weight', 'base_model.model.layers.29.mlp.up_proj.weight', 'base_model.model.layers.29.input_layernorm.weight', 'base_model.model.layers.29.post_attention_layernorm.weight', 'base_model.model.layers.30.self_attn.q_proj.weight', 'base_model.model.layers.30.self_attn.k_proj.weight', 'base_model.model.layers.30.self_attn.v_proj.weight', 'base_model.model.layers.30.self_attn.o_proj.weight', 'base_model.model.layers.30.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.30.mlp.gate_proj.weight', 'base_model.model.layers.30.mlp.down_proj.weight', 'base_model.model.layers.30.mlp.up_proj.weight', 'base_model.model.layers.30.input_layernorm.weight', 'base_model.model.layers.30.post_attention_layernorm.weight', 'base_model.model.layers.31.self_attn.q_proj.weight', 'base_model.model.layers.31.self_attn.k_proj.weight', 'base_model.model.layers.31.self_attn.v_proj.weight', 'base_model.model.layers.31.self_attn.o_proj.weight', 'base_model.model.layers.31.self_attn.rotary_emb.inv_freq', 'base_model.model.layers.31.mlp.gate_proj.weight', 'base_model.model.layers.31.mlp.down_proj.weight', 'base_model.model.layers.31.mlp.up_proj.weight', 'base_model.model.layers.31.input_layernorm.weight', 'base_model.model.layers.31.post_attention_layernorm.weight', 'base_model.model.norm.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.1194e-02, -1.8372e-03,  1.5615e-02,  ...,  1.4414e-02,\n",
      "          6.1241e-03,  1.5570e-02],\n",
      "        [-7.6161e-03,  6.2772e-03, -1.3879e-02,  ...,  9.2896e-03,\n",
      "         -1.0831e-06, -4.9550e-04],\n",
      "        [-1.4587e-02, -6.9995e-03,  1.2557e-02,  ...,  7.8875e-03,\n",
      "         -7.2573e-03, -7.3969e-03],\n",
      "        ...,\n",
      "        [-9.9545e-03, -3.0631e-04,  7.9381e-03,  ...,  3.1013e-03,\n",
      "         -1.4561e-02, -8.1029e-03],\n",
      "        [ 8.7975e-03, -9.5347e-03, -8.2265e-03,  ..., -1.1474e-02,\n",
      "          8.0903e-03, -1.3070e-02],\n",
      "        [ 7.1723e-03, -2.7537e-03, -9.7997e-03,  ..., -3.1994e-03,\n",
      "          1.1245e-02, -1.3780e-02]])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if 'lora' in n:\n",
    "        print(p)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1194e-02, -1.8372e-03,  1.5615e-02,  ...,  1.4414e-02,\n",
       "          6.1241e-03,  1.5570e-02],\n",
       "        [-7.6161e-03,  6.2772e-03, -1.3879e-02,  ...,  9.2896e-03,\n",
       "         -1.0831e-06, -4.9550e-04],\n",
       "        [-1.4587e-02, -6.9995e-03,  1.2557e-02,  ...,  7.8875e-03,\n",
       "         -7.2573e-03, -7.3969e-03],\n",
       "        ...,\n",
       "        [-9.9545e-03, -3.0631e-04,  7.9381e-03,  ...,  3.1013e-03,\n",
       "         -1.4561e-02, -8.1029e-03],\n",
       "        [ 8.7975e-03, -9.5347e-03, -8.2265e-03,  ..., -1.1474e-02,\n",
       "          8.0903e-03, -1.3070e-02],\n",
       "        [ 7.1723e-03, -2.7537e-03, -9.7997e-03,  ..., -3.1994e-03,\n",
       "          1.1245e-02, -1.3780e-02]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['base_model.model.layers.0.self_attn.k_proj.lora_A.default.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1198e-02, -1.8330e-03,  1.5624e-02,  ...,  1.4411e-02,\n",
       "          6.1283e-03,  1.5579e-02],\n",
       "        [-7.6152e-03,  6.2727e-03, -1.3887e-02,  ...,  9.2982e-03,\n",
       "         -1.1437e-05, -5.0887e-04],\n",
       "        [-1.4586e-02, -7.0003e-03,  1.2569e-02,  ...,  7.8880e-03,\n",
       "         -7.2497e-03, -7.3856e-03],\n",
       "        ...,\n",
       "        [-9.9548e-03, -3.0787e-04,  7.9469e-03,  ...,  3.0999e-03,\n",
       "         -1.4552e-02, -8.0941e-03],\n",
       "        [ 8.8106e-03, -9.5266e-03, -8.2273e-03,  ..., -1.1473e-02,\n",
       "          8.0957e-03, -1.3063e-02],\n",
       "        [ 7.1870e-03, -2.7483e-03, -9.8101e-03,  ..., -3.1905e-03,\n",
       "          1.1243e-02, -1.3782e-02]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['base_model.model.layers.0.self_attn.k_proj.lora_A.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, PeftModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isfile('/data/gj/Bi-Attention-HFTrainer/output_dir/test/checkpoint-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a': 1}\n",
    "b = {'b': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b_c': 2, 'b_d_e': 3, 'f': 4}\n"
     ]
    }
   ],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = {}\n",
    "    for key, value in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n",
    "        if isinstance(value, dict):\n",
    "            items.update(flatten_dict(value, new_key, sep=sep))\n",
    "        else:\n",
    "            items[new_key] = value\n",
    "    return items\n",
    "\n",
    "# 示例嵌套字典\n",
    "nested_dict = {\n",
    "    'a': 1,\n",
    "    'b': {\n",
    "        'c': 2,\n",
    "        'd': {\n",
    "            'e': 3\n",
    "        }\n",
    "    },\n",
    "    'f': 4\n",
    "}\n",
    "\n",
    "# 调用函数摊平字典\n",
    "flat_dict = flatten_dict(nested_dict)\n",
    "print(flat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import os \n",
    "\n",
    "os.environ['http_proxy'] = '10.40.50.225:7890'\n",
    "os.environ['https_proxy'] = '10.40.50.225:7890'\n",
    "acc = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 7.36k/7.36k [00:00<00:00, 8.44MB/s]\n"
     ]
    }
   ],
   "source": [
    "recall = evaluate.load('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,0,1]\n",
    "b = [0,1,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = acc.compute(predictions=a, references=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = precision.compute(predictions=a, references=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = recall.compute(predictions=a, references=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.update(y)\n",
    "x.update(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': 0.5, 'precision': 1.0, 'accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 3, 'c': 4}\n"
     ]
    }
   ],
   "source": [
    "dict1 = {'a': 1, 'b': 2}\n",
    "dict2 = {'b': 3, 'c': 4}\n",
    "\n",
    "merged_dict = {key: value for d in [dict1, dict2] for key, value in d.items()}\n",
    "print(merged_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors.torch\n",
    "\n",
    "model = safetensors.torch.load_file('/data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200/model.safetensors', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': tensor([-0.0012, -0.0057]),\n",
       " 'weight': tensor([[ 0.0143,  0.0015, -0.0131,  ..., -0.0001, -0.0145,  0.0036],\n",
       "         [-0.0092, -0.0137,  0.0185,  ...,  0.0116,  0.0198,  0.0063]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200 does not appear to have a file named config.json. Checkout 'https://huggingface.co//data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/data/gj/Bi-Attention-HFTrainer/test.ipynb 单元格 83\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.10.80.35/data/gj/Bi-Attention-HFTrainer/test.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModel\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.10.80.35/data/gj/Bi-Attention-HFTrainer/test.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39m/data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/biattention/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:441\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[39mif\u001b[39;00m kwargs_copy\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    439\u001b[0m         _ \u001b[39m=\u001b[39m kwargs_copy\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    442\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    443\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    444\u001b[0m         trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[1;32m    445\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    446\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs_copy,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/biattention/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:916\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    915\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 916\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    918\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/biattention/lib/python3.9/site-packages/transformers/configuration_utils.py:573\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    572\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    575\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/biattention/lib/python3.9/site-packages/transformers/configuration_utils.py:628\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m configuration_file \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_configuration_file\u001b[39m\u001b[39m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    626\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    629\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    630\u001b[0m         configuration_file,\n\u001b[1;32m    631\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    632\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    633\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    634\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    635\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    636\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    637\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    638\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    639\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    640\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    642\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    643\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/biattention/lib/python3.9/site-packages/transformers/utils/hub.py:380\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 380\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    381\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named \u001b[39m\u001b[39m{\u001b[39;00mfull_filename\u001b[39m}\u001b[39;00m\u001b[39m. Checkout \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    382\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available files.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m         )\n\u001b[1;32m    384\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: /data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200 does not appear to have a file named config.json. Checkout 'https://huggingface.co//data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200/None' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained('/data/gj/Bi-Attention-HFTrainer/output_dir/naive-vicuna-bi-nlu/checkpoint-7200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biattention",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
